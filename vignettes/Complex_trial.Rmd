---
title: "Untitled"
author: "Lisamaria Eble"
date: "25-07-2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE)
```

This guide describes how to implement a more complex trial design with two special features, the delayed start of a fourth cohort depending on the outcome of the first cohort and a SuperGo decision influencing the further recruitment of the first cohort.  

Further information about the functions of the package [bhmbasket](https://cran.r-project.org/web/packages/bhmbasket/index.html) and how to set up an instructive trial example, can be found in the vignette [Getting started](...).  

## Trial Design

The example trial consists of four cohorts with a planned total of 70, 25, 25, and 25 subjects.
The first cohort will be analysed in a futility analysis after 12 subjects.
The second and third cohorts are assumed to have all 25 subjects recruited at that time.
Recruitment of the fourth cohort is depended on Cohort 1 passing its futility analysis and by the time of the 2nd analysis of Cohort 1, Cohort 4 is expected to be fully recruited.
Before all cohorts will be analysed in a primary analysis, Cohort 1 will have a SuperGo decision as additional decision outcome. 
Does Cohort 1 achieves a SuperGo, 58 subjects will be recruited immediately.
Does Cohort 1 not reach a SuperGo, but a Go, only 13 additional subjects will be recruited and the primary analysis will be performed.
After passing this analysis, Cohort 1 will recruit further 45 subjects.
Cohort 1 is then fully recruited and will have a final analysis.
The trial design of this example study is depicted on Figure 1.

<center>
<img src="C:\Users\eblelisa\OneDrive - Boehringer Ingelheim\Documents\bhmbasketVignette\ComplexExample.png" width="85%" height="85%"/>  
Figure 1: Example Trial Design
</center>


## Prerequisites

```{r, message=FALSE, warning=FALSE}
library(bhmbasket)
set.seed(1705)
```

The function `performAnalyses()` is set up for parallel execution, which can be leveraged by providing a parallel backend that is accepted by the foreach framework, as e.g. provided by the R package [doFuture](https://cran.r-project.org/web/packages/doFuture/vignettes/doFuture.html):

```{r, message=FALSE, warning=FALSE}
library(doFuture)

registerDoFuture()
plan(multisession)
```

## First Simulations

The setup of the trial design starts with the simulation of scenario data with the function `simulateScenarios()`.
In this example there are four cohorts included, whereby the fourth one will start later and is filtered by taking out the fourth entry of the number of subjects and target rates.
The cohorts will be simulated in four different scenarios, a positive scenario, a SuperGo scenario, a nugget scenario, and a negative scenario. 

```{r}
## scenarios
orr_scenario_list <- list(
  orr_positive_scenario   = c(0.35, 0.3, 0.2,  0.2),
  orr_super_go_scenario   = c(0.45, 0.4, 0.2,  0.2),
  orr_nugget_scenario     = c(0.35, 0.3, 0.05, 0.05),
  orr_negative_scenario   = c(0.15, 0.1, 0.05, 0.05))

## target rates
orr_target_rates <- c(0.35, 0.3, 0.2, 0.2)

## N subjects
n_subjects_Ph1 <- c(12, 25, 25, 0)

## simulation
scenarios_futility_1 <- simulateScenarios(
  n_subjects_list     = n_subjects_Ph1[-4],
  response_rates_list = lapply(orr_scenario_list, function (x) x[-4]),
  n_trials = 1000)

scenarios_futility_1
```

### Analysis I

The first analysis will be performed after Cohort 1 has 12 subjects recruited.
The function `performAnalyses()` analyses all cohorts (except Cohort 4) with 10 000 MCMC iterations.
In this case, the model *ExNex adjusted* is used, a combination of the Bayesian hierarchical models (BHM) proposed by [Berry et al. (2013)](https://journals.sagepub.com/doi/10.1177/1740774513497539) and *ExNex*, the BHM proposed by [Neuenschwander et al. (2016)](https://onlinelibrary.wiley.com/doi/10.1002/pst.1730)).

```{r, message=FALSE, warning=FALSE}
analyses_futility_1 <- performAnalyses(
  scenario_list     = scenarios_futility_1,
  method_names      = "exnex_adj",
  target_rates      = orr_target_rates[-4])

analyses_futility_1
```

One can get point estimates and credible intervals per cohorts, as well as estimated biases and mean squared errors of the point estimators using the function `getEstimates(analyses_futility_1)`.

#### Decision Making

The created analyses list will be used to make Go/NoGo decisions as part of the futility analysis.
In this case, decisions for Cohort 2 and 3 are not of interest and therefore, the argument `boundary_rules` obtains `TRUE` at the second and third position.
The decision rule for Cohort 1 is implemented as follows:

$P(p_1|\text{data} > 0.2) > 0.5$

```{r}
go_decisions_futility_1 <- getGoDecisions(
  analyses_list   = analyses_futility_1,
  cohort_names    = "p_1",
  evidence_levels = 0.5,
  boundary_rules  = quote(c(x[1] >= 0.2, TRUE, TRUE)))

go_decisions_futility_1
```

##### SuperGo

After the first Go/NoGo decision making, an additional SuperGo decision making will be performed, implementing different decision boundaries.
In general, the SuperGo outcome can be used for a potential accelerated approval or to skip directly to the next Phase.
In this case, Cohort 1 will have the next Phase directly after reaching a SuperGo in this futility analysis without a second analysis.
The boundary rules of the SuperGo decision are implemented in the same way as above: 

$P(p_1|\text{data} > 0.33) > 0.5$
```{r}
go_decisions_SuperGo <- getGoDecisions(
  analyses_list   = analyses_futility_1,
  cohort_names    = "p_1",
  evidence_levels = 0.5,
  boundary_rules  = quote(c(x[1] >= 0.33, TRUE, TRUE)),
  overall_min_gos = 3)

go_decisions_SuperGo
```

The Go probabilities of this SuperGo decision is lower than the probabilities of the previous Go/NoGo decision, as expected.
To make sure that there are not more SuperGo decisions than Go decisions in this two decision lists, a sanity check is performed.

```{r}
## sanity check: go probability in PoCP always greater than or equal to SuperGo probability
all(
  sapply(seq_along(scenarios_futility_1), function (i) getGoProbabilities(go_decisions_futility_1)[[1]][[i]])[1, ] >=
    sapply(seq_along(scenarios_futility_1), function (i) getGoProbabilities(go_decisions_SuperGo)[[1]][[i]])[1, ])
```

### Add new Cohort

After Cohort 1 passed the futility analysis, Cohort 4 will be included.
Therefore, the decision list must be manipulated.
This includes adding scenario data of another cohort as well as decisions, which are necessary for the subsequent continuation of recruitment. 
The decision list will be copied in `go_decisions_1` and adjusted for each scenario. 

```{r}
go_decisions_1 <- go_decisions_futility_1
```

The first step is to combine the already existing decisions of the futility analysis with decisions for Cohort 4.
Cohort 4 is taking over the decisions of Cohort 1, due to the prerequisite that the start of Cohort 4 depends on Cohort 1 passing its futility analysis.

```{r}
go_decisions_1[[1]]$decisions_list$exnex_adj <-
    cbind(go_decisions_1[[1]]$decisions_list$exnex_adj[, c(1, 2, 3, 4)],
          "decision_4" = go_decisions_futility_1[[1]]$decisions_list$exnex_adj[, 2])

head(go_decisions_1[[1]]$decisions_list$exnex_adj)
```

The second step is to adapt the scenario data.
This contains the amendment of the number of subjects and responders as well as the response rates.
Due to the aforementioned precondition between the start of Cohort 4 and the futility analysis of Cohort 1, the number of subjects and responders of Cohort 4 are initially 0.
This ensures that, using the function `continueRecruitment()`, Cohort 4 will only recruit subjects if Cohort 1 passed the futility analysis.

Implementation for number of subjects:
```{r}
go_decisions_1[[1]]$scenario_data$n_subjects <- 
    cbind(go_decisions_futility_1[[1]]$scenario_data$n_subjects[, c(1, 2, 3)],
          "n_4" = 0)
  
head(go_decisions_1[[1]]$scenario_data$n_subjects)
```

The entire implementation of the manipulation of the decision list is implemented in a for loop, due to the number of scenarios:
 
```{r}
go_decisions_1 <- go_decisions_futility_1
for (s in seq_along(orr_scenario_list)) {
  
  ## add go decisions
  go_decisions_1[[s]]$decisions_list$exnex_adj <-
    cbind(go_decisions_1[[1]]$decisions_list$exnex_adj[, c(1, 2, 3, 4)],
          "decision_4" = go_decisions_futility_1[[1]]$decisions_list$exnex_adj[, 2])
  
  ## add additional cohort in scenarios
  ### subjects
  go_decisions_1[[s]]$scenario_data$n_subjects <- 
    cbind(go_decisions_futility_1[[1]]$scenario_data$n_subjects[, c(1, 2, 3)],
          "n_4" = 0)
  
  ### responders
  go_decisions_1[[s]]$scenario_data$n_responders <- 
    cbind(go_decisions_futility_1[[s]]$scenario_data$n_responders[, c(1, 2, 3)],
          "r_4" = 0)
  
  ### response rates
  go_decisions_1[[s]]$scenario_data$response_rates <-
    matrix(orr_scenario_list[[s]], byrow = TRUE, nrow = 1)
  colnames(go_decisions_1[[s]]$scenario_data$response_rates) <- paste0("rr_", 1:4)
  
}
rm(s)
```

### Continue Recruitment

The recruitment can be continued, once the futility analysis is performed and the decision list is adapted. 
Cohort 1 will recruit additional 13 subjects and Cohort 4 will recruit 25 subjects.
In both cases, only the trial outcomes that reached a Go in the previous futility analysis will recruit additional subjects and will be analysed afterwards.

```{r, include = FALSE}
set.seed(1705)
```

```{r}
## add 13 subjects for Cohort 1 and 25 subjects for Cohort 4
scenarios_2 <- continueRecruitment(
  n_subjects_add_list = c(13, 0, 0, 25),
  decisions_list      = go_decisions_1,
  method_name         = "exnex_adj")

scenarios_2
```

### Analysis II

In the primary analysis II, all cohorts will be analysed with the model *ExNex adjusted* with a subsequent decision making.

```{r, message=FALSE, warning=FALSE}
analyses_2 <- performAnalyses(
  scenario_list     = scenarios_2,
  method_names      = "exnex_adj",
  evidence_levels   = 0.75,
  target_rates      = orr_target_rates)

analyses_2
```

#### Decision Making

The second decision making is part of analysis II.
The decision is based on all 4 cohorts applying different decision boundaries.
It is the final decision making for Cohort 2, 3, and 4, and therefore, it is a three-way decision making with Go, Consider, and NoGo outcomes for these cohorts.

```{r}
go_decisions_2 <- getGoDecisions(
  analyses_list   = analyses_2,
  cohort_names    = c("p_1", "p_2", "p_3", "p_4"),
  evidence_levels = rep(0.75, 4),
  boundary_rules  = quote(c(x[1] >= 0.17,
                            x[2] >= 0.18,
                            x[3] >= 0.1,
                            x[4] >= 0.1)))

nogo_decisions_2 <- getGoDecisions(
  analyses_list      = analyses_2,
  cohort_names       = c("p_1", "p_2", "p_3", "p_4"),
  evidence_levels    = rep(0.75, 4),
  boundary_rules     = quote(c(x[1] >= 0.17,
                               x[2] >= 0.1,
                               x[3] >= 0.05,
                               x[4] >= 0.05)))

nogo_decisions_2 <- negateGoDecisions(nogo_decisions_2)

decision_2 <- getGoProbabilities(go_decisions_2, nogo_decisions_2)
scaleRoundList(decision_2, round_digits = 2)
```

## Second Simulations

In the next Phase, Cohort 1 will recruit additional 45 subjects.
The precondition for this recruitment is a SuperGo in the futility analysis or a Go in analysis II.
Due to this precondition, the decision list must be modified again:

```{r}
go_decisions_for_analysis_3 <- go_decisions_2
for (s in seq_along(orr_scenario_list)) {
  
  ## Go in Cohort 1 or SuperGo in Cohort 1
  go_decisions_for_analysis_3[[s]]$decisions_list$exnex_adj[, 2] <-
    go_decisions_2[[s]]$decisions_list$exnex_adj[, 2] + 
    go_decisions_SuperGo[[s]]$decisions_list$exnex_adj[, 2] > 0
  
  ## for overall Go as well:
  go_decisions_for_analysis_3[[s]]$decisions_list$exnex_adj[, 1] <-
    go_decisions_2[[s]]$decisions_list$exnex_adj[, 1] + 
    go_decisions_SuperGo[[s]]$decisions_list$exnex_adj[, 1] > 0
  
}
rm(s)
```

The modified decision list can be used for the continuation of recruitment fulfilling the aforementioned precondition.

```{r, include = FALSE}
set.seed(1705)
```

```{r}
scenarios_3 <- continueRecruitment(
  n_subjects_add_list = c(45, 0, 0, 0),
  decisions_list      = go_decisions_for_analysis_3,
  method_name         = "exnex_adj")

scenarios_3
```

**Include?**  
If one is interested in the mean number of subjects per scenario, one can get an overview with function `getAverageNSubjects()`.
```{r}
## mean number of subjects per scenario in Phase 2
getAverageNSubjects(scenarios_3)
```

### Analysis III

The primary analysis III is only based on Cohort 1.

```{r, message=FALSE, warning=FALSE}
analyses_3 <- performAnalyses(
  scenario_list         = scenarios_3,
  method_names          = c("exnex_adj", "stratified"),
  target_rates          = orr_target_rates)

analyses_3
```

#### Decision Making

The decision making of Analysis 3 is divided into a final analysis and a sensitivity analysis.
The final decision rules for Cohort 1 are proposed by [Fisch et al. (2015)](https://link.springer.com/article/10.1177/2168479014533970), using the model *ExNex adjusted*.
Further information on how to apply these rules proposed by Fisch et al. are available in the vignette [Getting started](...) of the package bhmbasket.
The decision rules are based on relevance and significance, as follows:

Relevance:    $P(p_1|\text{data} > 0.3) > 0.5$  
Significance: $P(p_1|\text{data} > 0.15) > 0.95$

The second part of the analysis is the sensitivity analyses, which is performed to make sure, which effect should be expected in the study.
No borrowing is required between the cohorts, thus the model *stratified* is used.
The decision rules for the sensitivity analysis looks as follows:

Go:   $P(p_1|\text{data} > 0.25) > 0.9$  
NoGo: $P(p_1|\text{data} > 0.15) > 0.9$ 

```{r}
go_decisions_3  <- getGoDecisions(
  analyses_list   = analyses_3,
  cohort_names    = c("p_1", "p_1", "p_1"),
  evidence_levels = c(0.5, 0.9, 0.9),
  boundary_rules  = list(quote(c(x[1] >= 0.305 & x[2] > 0.15, TRUE, TRUE, TRUE)),  # final analysis: exnex
                         quote(c(x[3] >= 0.25,                TRUE, TRUE, TRUE)))) # sensitivity analysis: stratified

nogo_decisions_3  <- negateGoDecisions(
  getGoDecisions(
    analyses_list   = analyses_3,
    cohort_names    = c("p_1", "p_1", "p_1"),
    evidence_levels = c(0.5, 0.9, 0.9),
    boundary_rules  = list(quote(c(x[1] >= 0.305 | x[2] > 0.15, TRUE, TRUE, TRUE)),   # final analysis: exnex
                           quote(c(x[3] >= 0.15,                TRUE, TRUE, TRUE))))) # sensitivity analysis: stratified

final_probability_list <- getGoProbabilities(go_decisions_3, nogo_decisions_3)

scaleRoundList(final_probability_list, round_digits = 2)
```

In case of the final analysis, the set of decision rules leads to an overall Go probability of 98% and individual Go probability of 71% in Cohort 1. 
The probabilities of identifying the nugget cohorts are 70% and 69%.
The overall Go probability in the negative scenario is 3%.

The sensitivity analysis is adapted to the negative scenario of the final analysis. 
Thus, the overall Go probability is 3%.
However, the individual Go probability of Cohort 1 is xx%. 

... Interpretation ...
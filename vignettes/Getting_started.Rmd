---
title: "bhmbasket - Getting Started"
author: "Lisamaria Eble"
date: "28-06-2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE)
```


This guide provides an overview of the R package [bhmbasket](https://cran.r-project.org/web/packages/bhmbasket/index.html) on how to use its functions to evaluate the operating characteristics of a basket trial.
The design of the example trial is depicted on Figure 1.
The example trial consists of three cohorts included in the trial, and the third cohort is already observed historical data.
Cohort 1 and 2 will be analyzed in a futility analysis with simple Bayesian Go/NoGo decision making after 10 subjects have been recruited in each cohort.
Based on the futility analysis, the recruitment will continue until 10 and 15 additional subjects were recruited in Cohort 1 and 2, respectively.
The final analysis will be performed with Go/NoGo decision making according to [Fisch et al. (2015)](https://link.springer.com/article/10.1177/2168479014533970).


<center>
<img src="C:\Users\eblelisa\OneDrive - Boehringer Ingelheim\Pictures\TrialExample.png" width="70%" height="70%"/>  
Figure 1: Trial design
</center>


## Overview and Workflow

Figure 2 depicts the main functions and the workflow of the package.
The first step is to simulate scenarios with `simulateScenarios()`.
The simulated trial outcomes are analyzed with Bayesian hierarchical models (BHMs) with `performAnalyses()`.
The user can then apply the decision making framework with `getGoDecisions()` to calculate decision probabilities using `getGoProbabilities()` and to recruit additional patients with `continueRecruitment()` for subsequent analyses.

<center>
<img src="C:\Users\eblelisa\OneDrive - Boehringer Ingelheim\Documents\bhmbasketVignette\bhmbasketOverview.png" width="60%" height="60%"/>
  
Figure 2: Workflow of bhmbasket <br>
*Solid lines: core functions; dashed lines: optional functions*
</center>


## Prerequisites

```{r, message=FALSE, warning=FALSE}
library(bhmbasket)
set.seed(1705)
```

The function `performAnalyses()` is set up for parallel execution, which can be leveraged by providing a parallel backend that is accepted by the foreach framework, as e.g. provided by the R package [doFuture](https://cran.r-project.org/web/packages/doFuture/vignettes/doFuture.html):

```{r, message=FALSE, warning=FALSE}
library(doFuture)

registerDoFuture()
plan(multisession)
```

## Simulation of Scenarios

The function `simulateScenarios()` is used to simulate scenario data according to scenarios.
One must provide the number of subjects and the true response rates per cohort.
Historical data can be included in the simulated trial outcomes.

This example consists of four scenarios and three cohorts, whereby the third cohort is historical with a fixed number of five responders.

The trial design will be investigated with a positive, two nugget, and a negative scenario.
The positive and negative scenarios cover the highest and lowest response rates that lead to a continuation or stop of the trial, respectively.
In the nugget cases, only one cohort assumes the positive response rate, whereas the other cohorts assume the negative response rates. 

```{r}
scenarios_list <- list(
  rr_positive = c(0.2, 0.35, 5),
  rr_nugget1  = c(0.2, 0.15, 5),
  rr_nugget2  = c(0.1, 0.35, 5),
  rr_negative = c(0.1, 0.15, 5))

scenario_list <- simulateScenarios(
  n_subjects_list     = c(10, 10, 15),
  response_rates_list = scenarios_list)
```

<!-- The function distinguishes historical data from the data to be simulated by the response rate argument. -->
<!-- If the vector providing the scenario response rates contains an integer, it will be identified as the number of historical responders.   -->


<!-- If the number of subjects is not the same for all scenarios, one has to provide a list of vectors with the number of subjects of each scenario. -->

### Observed Outcome Data
In addition to assessing the operating characteristics of a basket trial, an observed trial outcome can be analyzed as well.
It can be specified with the function `createTrial()` as shown below.

<!-- The package provides the possibility to analyse simulated, observed and historical data. -->
<!-- The function `simulateScenarios()` is used for data to be simulated and historical data as shown above. -->
<!-- The function `createTrial()` is used for observed data and creates only a single trial outcome. -->
<!-- In both cases, one has to specify the number of subjects and the response rates or the number of responders and the result will be a list of the class scenario list, that can be further used. -->

```{r}
trial_outcome <- createTrial(n_subjects   = c(10, 20, 30, 40),
                             n_responders = c( 1,  2,  3,  4))
```

The created trial outcome can be processed in the same way as the simulated trial outcomes generated by `simulateScenarios()` as shown in the next section.

## Analyses

The function [`performAnalyses()`](https://search.r-project.org/CRAN/refmans/bhmbasket/html/performAnalyses.html) approximates the posterior distribution for each trial realization via MCMC sampling and returns the quantiles of the posterior response rates among other outcome parameters.
Required arguments are the created scenario list, the name of at least one analysis method and the target rates per cohort:

```{r, include = FALSE}
## dummy code to avoid loading package messages triggered by 1st run of performAnalyses()
dummy_list <- createTrial(c(10, 10), c(1, 2))
performAnalyses(
  scenario_list    = dummy_list,
  method_names     = c("berry"),
  target_rates     = c(0.5, 0.5))
```

```{r, warning = FALSE}
analysis_list <- performAnalyses(
  scenario_list    = scenario_list,
  method_names     = c("berry", "exnex_adj", "stratified"), 
  calc_differences = c(2, 1),
  target_rates     = c(0.2, 0.35, 0.3))
```

Available methods are the BHM proposed by [Berry et al. (2013)](https://journals.sagepub.com/doi/10.1177/1740774513497539)) (*berry*), the BHM proposed by [Neuenschwander et al. (2016)](https://onlinelibrary.wiley.com/doi/10.1002/pst.1730)) (*exnex*), and a BHM that combines both approaches called exnex adjusted (*exnex_adj*), as well as the two beta-binomial approaches *pooled* and *stratified*.
The target rates are required for the methods *berry* and *exnex adjusted* as well as for setting default prior parameters for the analysis models.
One can use [`getPriorParameters()`](https://search.r-project.org/CRAN/refmans/bhmbasket/html/getPriorParameters.html) and the `setPriorParameters...()` family of functions for a custom choice of prior parameters.
Additional evidence levels can be provided to the default evidence levels.
Furthermore, differences of cohorts can be calculated using the argument `calc_differences`. For example, for the difference between cohort x and y, one uses `calc_differences = c(x, y)`.
This can be used to compare outcomes of cohorts directly, e.g. when comparing cohorts with monotreatment and cohorts with combination treatment.

### Getting Estimates   

The user can get estimates of the model parameters with [`getEstimates()`](https://search.r-project.org/CRAN/refmans/bhmbasket/html/getEstimates.html). 
The standard parameters are point estimates and credible intervals per cohorts, as well as estimated biases and mean squared errors of the point estimators.
The list of shown parameters can be expanded by additional model parameters using the argument `add_parameters`.
  
```{r}
estimates <- getEstimates(
  analyses_list  = analysis_list,
  add_parameters = c("mu", "tau"))
round(estimates$exnex_adj$scenario_3, digits = 2)
```
  
## Decision Making  

Go/NoGo decision rules can be implemented with [`getGoDecisions()`](https://search.r-project.org/CRAN/refmans/bhmbasket/html/getGoDecisions.html).
The function calculates Go decisions for each cohort of a trial outcome based on decision rules.
The resulting decision list can be used to calculate the cohort-wise and overall decision probabilities using the functions [`getGoProbabilities()`](https://search.r-project.org/CRAN/refmans/bhmbasket/html/getGoProbabilities.html) and [`negateGoDecisions()`](https://search.r-project.org/CRAN/refmans/bhmbasket/html/negateGoDecisions.html).
 

### Implementation of Decision Rules in General

A Bayesian decision rule is generally defined as follows:
$$P(p_j|\text{data} > p_{Bj}) > \gamma_j,$$

where $p_j|\text{data}$ is the posterior response rate of cohort $j$, and $\gamma_j$ and $p_{Bj}$ are its evidence level and decision boundary, respectively.

<!-- This rule may be rewritten with the 1-$\gamma$-quantile of the posterior response rate of cohort $j$ as follows: -->

<!-- $$q_{1-\gamma_j} > p_{Bj}$$   -->

#### Example Decision

Three arguments are used to implement such a decision rule with `getGoDecisions()`, namely the cohort names, the evidence levels, and the boundary rules.

As an example, the decision rules $P(p_1|\text{data} > 0.1) > 0.5$ and $P(p_2|\text{data} > 0.2) > 0.9$ would be implemented with the arguments of `getGoDecisions()` as follows:

```{r, eval=FALSE}
cohort_names    = c('p_1', 'p_2')
evidence_levels = c(0.5, 0.9)
boundary_rules  = quote(c(x[1] > 0.1), x[2] > 0.2)
```

The first evidence level `0.5` and the first cohort name `p_1` are addressed by `x[1]`.
Accordingly, the evidence level `0.9` and the second cohort name `p_2` are addressed by `x[2]`.
Inside the quote for the boundary rule, `x[1]` and `x[2]` can be used in any order, and the rules can be nested, or conditioned, which makes this approach very flexible for implementing different decision rules.


#### Futility Analysis

The first decision making in this example is part of the futility analysis.
The function `getGoDecisions()` creates the Go decisions for the specified cohorts with the rules outlined above:  

Cohort 1: $P(p_1|\text{data} > 0.11) > 0.5$  
Cohort 2: $P(p_2|\text{data} > 0.22) > 0.5$  

Note that there must be a decision rule specified for each cohort in the trial, i.e., the vector in the quote must have the same length as the number of cohorts in the trial. 
In this example, the third cohort should not get a decision in the futility analysis.
Therefore, the argument `boundary_rules` contains the value `TRUE` on the third position.
To assess the overall futility operating characteristics, the required number of cohort-wise Go decisions for an overall Go is increased to two.

```{r}
futility_decision_list <- getGoDecisions(
  analyses_list   = analysis_list,
  cohort_names    = c("p_1", "p_2"),
  evidence_levels = c(0.5, 0.5),
  boundary_rules  = list(quote(c(x[1] > 0.11,
                                 x[2] > 0.22,
                                 TRUE))),
  overall_min_gos = 2)
```

The function `getGoProbability()` calculates the cohort-wise Go probabilities based on the previous created decisions list.
Optional, providing a NoGo decision list, the function can calculate additional NoGo probabilities using `negateGoDecisions()`.

```{r}
futility_go_probabilities <- getGoProbabilities(
   go_decisions_list = futility_decision_list)

scaleRoundList(futility_go_probabilities, round_digits = 2)
```

To compare the performance of different analysis models, it is possible to set up different decision rules for each method to calculate similar decision probabilities for a certain scenario.
In the example below, rules are specified for similar Go probabilities to compare the false Go probabilities of the different models (Scenario 4).

```{r}
decision_list_adj <- getGoDecisions(
  analyses_list   = analysis_list,
  cohort_names    = c("p_1", "p_2"),
  evidence_levels = c(0.5, 0.5),
  boundary_rules  = list(quote(c(x[1] > 0.12,
                                 x[2] > 0.23,
                                 TRUE)),      #berry
                         quote(c(x[1] > 0.11,
                                 x[2] > 0.21,
                                 TRUE)),      #exnex adjusted
                         quote(c(x[1] > 0.08,
                                 x[2] > 0.18,
                                 TRUE))),     #stratified
  overall_min_gos = 2)


go_probabilities <- getGoProbabilities(
  go_decisions_list = decision_list_adj)

scaleRoundList(go_probabilities, round_digits = 2)
```
The false Go probabilities of the method Stratified are comparatively high with 64% in Cohort 1 and 46% in Cohort 2.
Using the model ExNex adjusted leads to a false Go probability of 44% in Cohort 1 and 36% in Cohort 2.
The false Go probability in Cohort 1, using the model proposed by Berry et al. (2013), is xx percentage points lower compared to the probability when using the model ExNex adjusted.

The difference between the models can be attributed to the different amounts of borrowing of information between the cohorts.
The more borrowing, the smaller the false Go probability in the negative scenario.
Using the method Stratified leads to the highest false Go probabilities, which can be attributed to the absence of borrowing.
In this case, the model proposed by Berry et al. (2013) leads to the highest amount of borrowing and therefore, to the best outcome.
In case of ExNex adjusted, the amount of borrowing depends on the similarity of the cohorts. 
<!-- The more similar the cohorts, the higher the amount of borrowing. -->

### Continue Recruitment

After an analysis as above, one can continue the recruitment and add more subjects to the cohorts.
The function [`continueRecruitment()`](https://search.r-project.org/CRAN/refmans/bhmbasket/html/continueRecruitment.html) is used to update the scenario list and to add a specified number of subjects to the current number of subjects of the simulated cohorts.
Only the simulated trial outcomes with an overall Go decision will get additional subjects in the cohorts with cohort-wise Go decisions and only those trial outcomes will be analysed again in `performAnalyses()`.
`continueRecruitment()` only allows to add subjects according to one method.
In this case, *exnex adjusted* will be used to continue the recruitment.

```{r, message=FALSE, warning=FALSE}
final_scenario_list <- continueRecruitment(
  n_subjects_add_list = c(10, 15),
  decisions_list      = futility_decision_list,
  method_name         = "exnex_adj")
 
final_analysis_list <- performAnalyses(
  scenario_list = final_scenario_list, 
  method_names  = "exnex_adj",
  calc_differences = c(2, 1),
  target_rates  = c(0.2, 0.35, 0.3))
```


### Final Decision Making

In this example, decision making as proposed by [Fisch et al. (2015)](https://link.springer.com/article/10.1177/2168479014533970) is implemented for the final analysis.
This approach leads to a three-way decision making with Go, Consider, and NoGo outcomes based on decision rules labeled significance and relevance.
Each cohort will have a decision boundary for relevance and for significance.
To receive a Go decision, relevance and significance must be true.
If both criteria are false, the decision will be a NoGo.
If either relevance or significance is true, it will be a Consider.

#### Implementation of Decision Rules According to Fisch et al. (2015)

Decision rules following the framework proposed by Fisch et al. (2015) are implemented in a similar way as presented above.
<!-- To get a Consider decision and its probability, it is not enough to just negate the Go decision list, using `negateGoDecisions(decision_list)`. -->
<!-- It is necessary to set up another set of decision rules and negate them afterwards. -->
For each cohort, the Go and NoGo decision rules can be represented as a conjunction of relevance and significance. The set up of these rules is depict below.

Go: $R ∧ S$   
NoGo: $-R ∧ -S  = -(R ∨ S)$  
else Consider

To implement the NoGo rule, $-(R ∨ S)$, the function `negateGoDecisions()` can be used in conjunction with `getGoDecisions()`.
As an example, decision rules applying relevance and significance can be implemented as follows:

Relevance: $P(p_1|\text{data} > 0.8) > 0.5$  
Significance: $P(p_1|\text{data} > 0.4) > 0.95$


```{r, eval=FALSE}
cohort_names    = c('p_1', 'p_2',
                    'p_1', 'p_2')
evidence_levels = c(0.5, 0.5,
                    0.95, 0.95)

# argument for first call of getGoDecisions()
go_boundary_rules   = quote(c(x[1] > 0.8 & x[3] > 0.4, 
                              x[2] > 0.8 & x[4] > 0.4)

# argument for second call of getGoDecisions() with negateGoDecisions()
nogo_boundary_rules = quote(c(x[1] > 0.8 | x[3] > 0.4, 
                              x[2] > 0.8 | x[4] > 0.4)
```

#### Final Decision Example Trial

<!-- The decision making proposed by Fisch et al. (2015) implies that another set of decision rules is required as above. -->
<!-- The entire implementation of this decision rules is implemented as follows: -->

For the final analysis of this example, the decision rules for Cohort 1 for relevance and significance are $P(p_1|\text{data} > 0.2) > 0.5$ and $P(p_1|\text{data} > 0.1) > 0.95$, respectively.
In Cohort 2, the relevance criteria $P(p_2|\text{data} > 0.25) > 0.5$ ∧ $P(p_2-p_1|\text{data} > 0.1) > 0.5$ is a combination of boundary rules for the point estimate and the difference between Cohort 2 and 1.
The rules for significance is implemented with $P(p_2|\text{data} > 0.1) > 0.95$.
The third cohort should not get a decision as well as in the futility analysis and therefore, `boundary_rules` contains the value `TRUE` on the third position.


```{r}
final_decision_list <- getGoDecisions(
  analyses_list   = final_analysis_list,
  cohort_names    = c("p_1", "p_2", "p_diff_21", 
                      "p_1", "p_2"),
  evidence_levels = c(0.5, 0.5, 0.5,
                      0.8, 0.8),
  boundary_rules  = quote(c(x[1] > 0.13               & x[4] > 0.05,
                            x[2] > 0.26 & x[3] > 0.03 & x[5] > 0.14, 
                            TRUE)),
  overall_min_gos = 2)


final_nogo_decision_list <- negateGoDecisions(
  getGoDecisions(
    analyses_list   = final_analysis_list,
    cohort_names    = c("p_1", "p_2", "p_diff_21", 
                        "p_1", "p_2"),
    evidence_levels = c(0.5, 0.5, 0.5,
                        0.8, 0.8), 
    boundary_rules  = quote(c(x[1] > 0.13               | x[4] > 0.05,
                              x[2] > 0.26 & x[3] > 0.03 | x[5] > 0.14,
                              TRUE))),
  overall_min_nogos = 2)

final_probability_list <- getGoProbabilities(
  go_decisions_list = final_decision_list,
  nogo_decisions_list = final_nogo_decision_list)

scaleRoundList(final_probability_list, round_digits = 2)
```

It is always a trade-off sample size and required go probabilities.
In this case, the sets of decision rules lead to an overall Go probability of xx% and individual Go probabilities of xx% in Cohort 1 and xx% in Cohort 2. 
The probabilities of identifying the nugget cohorts are xx% and xx%.
In the negative scenario, the overall Go probability is xx%.

---
title: "bhmbasket - Getting Started"
author: "Lisamaria Eble"
date: "22-07-2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE)
```


This guide provides an overview of the R package [bhmbasket](https://cran.r-project.org/web/packages/bhmbasket/index.html) on how to use its functions to evaluate the operating characteristics of a basket trial with binary endpoints.
An example trial will be used to guide through the functions, the design of which is depicted in Figure 1.
The example trial consists of three cohorts where the third cohort is already observed historical data.
Cohorts 1 and 2 will be analyzed in a futility analysis using simple Bayesian Go/NoGo decision rules after 10 and 15 subjects have been recruited in Cohorts 1 and 2, respectively.
Based on the futility analysis, the recruitment will continue until 15 additional subjects are recruited in each cohort.
The final analysis will be performed with Go/NoGo decision rules according to [Fisch et al. (2015)](https://link.springer.com/article/10.1177/2168479014533970).


<center>
<img src="C:\Users\eblelisa\OneDrive - Boehringer Ingelheim\Pictures\TrialExample.png" width="70%" height="70%"/>  
Figure 1: Trial design
</center>


## Overview and Workflow

Figure 2 depicts the main functions and the workflow of the package.
The first step is to simulate scenarios with `simulateScenarios()`.
The simulated trial outcomes are analyzed with Bayesian hierarchical models (BHMs) using `performAnalyses()`.
The user can then specify and apply the decision rules with `getGoDecisions()` and can subsequently calculate decision probabilities using `getGoProbabilities()` and recruit additional patients with `continueRecruitment()` for later analyses.

<center>
<img src="C:\Users\eblelisa\OneDrive - Boehringer Ingelheim\Documents\bhmbasketVignette\bhmbasketOverview.png" width="60%" height="60%"/>
  
Figure 2: Workflow of bhmbasket <br>
*Solid lines: core functions; dashed lines: optional functions*
</center>


## Prerequisites

```{r, message=FALSE, warning=FALSE}
library(bhmbasket)
set.seed(677643)
```

The function `performAnalyses()` is set up for parallel execution, which can be leveraged by providing a parallel backend that is accepted by the foreach framework, as e.g. provided by the R package [doFuture](https://cran.r-project.org/web/packages/doFuture/vignettes/doFuture.html):

```{r, message=FALSE, warning=FALSE}
library(doFuture)

registerDoFuture()
plan(multisession)
```

## Simulation of Scenarios

The function `simulateScenarios()` is used to simulate data according to scenarios.
For each scenario, one must provide the number of subjects and the true response rates per cohort.
Historical data can be included in the simulated trial outcomes.

This example consists of four scenarios and three cohorts, whereby the third cohort is historical with a fixed number of five responders out of 15 subjects.
The trial design will be investigated with a positive scenario, two nugget scenarios, and a negative scenario.
The positive and negative scenarios cover the true highest and lowest response rates that lead to a continuation or stop, respectively, of the development of the drug.
In the nugget scenarios, only one of the cohorts assumes the positive response rate, whereas the other cohorts assume the negative response rates. 

```{r}
scenarios_list <- list(
  rr_positive = c(0.2, 0.35, 5),
  rr_nugget1  = c(0.2, 0.15, 5),
  rr_nugget2  = c(0.05, 0.35, 5),
  rr_negative = c(0.05, 0.15, 5))

scenario_list <- simulateScenarios(
  n_subjects_list     = c(15, 10, 15),
  response_rates_list = scenarios_list)

scenario_list
```

<!-- The function distinguishes historical data from the data to be simulated by the response rate argument. -->
<!-- If the vector providing the scenario response rates contains an integer, it will be identified as the number of historical responders.   -->


<!-- If the number of subjects is not the same for all scenarios, one has to provide a list of vectors with the number of subjects of each scenario. -->

### Observed Outcome Data
Also actual trial outcomes can be analyzed with [bhmbasket](https://cran.r-project.org/web/packages/bhmbasket/index.html).
An observed trial outcome can be specified with the function `createTrial()` as shown below.

<!-- The package provides the possibility to analyse simulated, observed and historical data. -->
<!-- The function `simulateScenarios()` is used for data to be simulated and historical data as shown above. -->
<!-- The function `createTrial()` is used for observed data and creates only a single trial outcome. -->
<!-- In both cases, one has to specify the number of subjects and the response rates or the number of responders and the result will be a list of the class scenario list, that can be further used. -->

```{r}
trial_outcome <- createTrial(n_subjects   = c(10, 20, 30, 40),
                             n_responders = c( 1,  2,  3,  4))
```

The created trial outcome can be processed in the same way as the simulated trial outcomes generated by `simulateScenarios()`.

## Analyses

The function [`performAnalyses()`](https://search.r-project.org/CRAN/refmans/bhmbasket/html/performAnalyses.html) approximates the joint posterior distribution for each trial realization via MCMC sampling and returns the quantiles of the marginal posterior response rates among other model parameters.
Required arguments are the scenario list created e.g. with `simulateScenarios()`, the name of at least one analysis method and the target rates per cohort.
In the example, the methods !!! TODO !!!

<!-- This should no longer be required with the latest package update -->
<!-- ```{r, include = FALSE} -->
<!-- ## dummy code to avoid loading package messages triggered by 1st run of performAnalyses() -->
<!-- dummy_list <- createTrial(c(10, 10), c(1, 2)) -->
<!-- performAnalyses( -->
<!--  scenario_list    = dummy_list, -->
<!--  method_names     = c("berry"), -->
<!--  target_rates     = c(0.5, 0.5)) -->
<!-- ``` -->

```{r, warning = FALSE}
analysis_list <- performAnalyses(
  scenario_list    = scenario_list,
  method_names     = c("berry", "exnex_adj", "stratified"), 
  calc_differences = c(2, 1),
  target_rates     = c(0.2, 0.35, 0.3))

analysis_list
```

Available methods are the BHM proposed by [Berry et al. (2013)](https://journals.sagepub.com/doi/10.1177/1740774513497539)) (*berry*), the BHM proposed by [Neuenschwander et al. (2016)](https://onlinelibrary.wiley.com/doi/10.1002/pst.1730)) (*exnex*), and a BHM that combines both approaches called exnex adjusted (*exnex_adj*), as well as the two beta-binomial approaches *pooled* and *stratified*.
The target rates are required for the methods *berry* and *exnex adjusted* as well as for setting default prior parameters for the analysis models.
One can use [`getPriorParameters()`](https://search.r-project.org/CRAN/refmans/bhmbasket/html/getPriorParameters.html) and the `setPriorParameters...()` family of functions for a custom choice of prior parameters.
Further evidence levels can be provided in addition to the default evidence levels.
Posterior differences of cohorts' response rates can be calculated using the argument `calc_differences`.
For example, for the difference between Cohort x and y, one uses `calc_differences = c(x, y)`.
This can be used to compare outcomes of cohorts directly, e.g. when comparing cohorts with monotreatment and cohorts with combination treatment.

### Getting Estimates   

The user can get estimates of the model parameters with [`getEstimates()`](https://search.r-project.org/CRAN/refmans/bhmbasket/html/getEstimates.html). 
The standard parameters are point estimates and credible intervals per cohorts, as well as estimated biases and mean squared errors of the point estimators.
The list of shown parameters can be expanded by additional model parameters using the argument `add_parameters`.
  
```{r}
estimates <- getEstimates(
  analyses_list  = analysis_list,
  add_parameters = c("mu", "tau"))
round(estimates$exnex_adj$scenario_3, digits = 2)
```
  
## Decision Making  

Go/NoGo decision rules can be implemented with [`getGoDecisions()`](https://search.r-project.org/CRAN/refmans/bhmbasket/html/getGoDecisions.html).
The function calculates Go decisions for each cohort of a trial outcome based on decision rules.
The resulting decision list can be used to calculate the cohort-wise and overall decision probabilities using the functions [`getGoProbabilities()`](https://search.r-project.org/CRAN/refmans/bhmbasket/html/getGoProbabilities.html) and [`negateGoDecisions()`](https://search.r-project.org/CRAN/refmans/bhmbasket/html/negateGoDecisions.html).

### Implementation of Decision Rules in General

A Bayesian decision rule is generally defined as follows:
$$P(p_j|\text{data} > p_{Bj}) > \gamma_j,$$

where $p_j|\text{data}$ is the posterior response rate of cohort $j$, and $\gamma_j$ and $p_{Bj}$ are its evidence level and decision boundary, respectively. 
This rule may be rewritten with the 1-$\gamma$-quantile of the posterior response rate of cohort $j$ as follows:

$$q_{1-\gamma_j} > p_{Bj}$$
As keeping the MCMC samples or marginal posterior densities of the parameters of interest would require too much memory, only pre-specifed quantiles of the MCMC samples are stored when applying [`performAnalyses()`](https://search.r-project.org/CRAN/refmans/bhmbasket/html/performAnalyses.html).

#### Example Decision Rule

Three arguments are used to implement such a decision rule with `getGoDecisions()`, namely the cohort names, the evidence levels, and the boundary rules.

As an example, the decision rules $P(p_1|\text{data} > 0.1) > 0.5$ and $P(p_2|\text{data} > 0.2) > 0.9$ would be implemented with the arguments of `getGoDecisions()` as follows:

```{r, eval=FALSE}
cohort_names    = c('p_1', 'p_2')
evidence_levels = c(0.5, 0.9)
boundary_rules  = quote(c(x[1] > 0.1), x[2] > 0.2)
```

The first evidence level `0.5` and the first cohort name `p_1` are addressed by `x[1]`.
Accordingly, the evidence level `0.9` and the second cohort name `p_2` are addressed by `x[2]`.
Inside the quote for the boundary rule, `x[1]` and `x[2]` can be used in any order, and the rules can be nested, or conditioned, which makes this approach very flexible for implementing different decision rules.


#### Futility Analysis

The first decision making in this example is part of the futility analysis.
The function `getGoDecisions()` creates the Go decisions for the specified cohorts with the rules outlined above:  

Cohort 1: $P(p_1|\text{data} > 0.11) > 0.5$  
Cohort 2: $P(p_2|\text{data} > 0.22) > 0.5$  

Note that there must be a decision rule specified for each cohort in the trial, i.e., the vector in the quote must have the same length as the number of cohorts in the trial. 
In this example, the third cohort should not get a decision.
Therefore, the argument `boundary_rules` contains the value `TRUE` on the third position.
To assess the overall futility operating characteristics, the required number of cohort-wise Go decisions for an overall Go is increased to two.

```{r}
futility_decision_list <- getGoDecisions(
  analyses_list   = analysis_list,
  cohort_names    = c("p_1", "p_2"),
  evidence_levels = c(0.5, 0.5),
  boundary_rules  = list(quote(c(x[1] > 0.12,
                                 x[2] > 0.22,
                                 TRUE))),
  overall_min_gos = 2)
```

The function `getGoProbability()` calculates the cohort-wise Go probabilities based on the previous created decisions list.
Optional, providing a NoGo decision list, the function can calculate additional NoGo probabilities using `negateGoDecisions()`.

```{r}
futility_go_probabilities <- getGoProbabilities(
   go_decisions_list = futility_decision_list)

scaleRoundList(futility_go_probabilities, round_digits = 2)
```

To compare the performance of different analysis models, it is possible to set up different decision rules for each method to calculate similar decision probabilities for a certain scenario.
In the example below, rules are specified for similar Go probabilities to compare the false Go probabilities of the different models (Scenario 4).

```{r}
decision_list_adj <- getGoDecisions(
  analyses_list   = analysis_list,
  cohort_names    = c("p_1", "p_2"),
  evidence_levels = c(0.5, 0.5),
  boundary_rules  = list(quote(c(x[1] > 0.14,
                                 x[2] > 0.24,
                                 TRUE)),      #berry
                         quote(c(x[1] > 0.1,
                                 x[2] > 0.21,
                                 TRUE)),      #exnex adjusted
                         quote(c(x[1] > 0.07,
                                 x[2] > 0.19,
                                 TRUE))),     #stratified
  overall_min_gos = 2)


#go_probabilities <- getGoProbabilities(
#  go_decisions_list = decision_list_adj)
#
#scaleRoundList(go_probabilities, round_digits = 2)

decision_list_adj
```
The false Go probabilities of the method Stratified are comparatively high with an overall Go of 55%, and 16% in Cohort 1 and 46% in Cohort 2.
Using the model ExNex adjusted leads to a false Go probability of 16% in Cohort 1 and 23% in Cohort 2.
The false Go probability in Cohort 1, using the model proposed by Berry et al. (2013), is 6 percentage points lower compared to the probability when using the model ExNex adjusted.

The difference between the models can be attributed to the different amounts of borrowing of information between the cohorts.
The more borrowing, the smaller the false Go probability in the negative scenario.
Using the method Stratified leads to the highest false Go probabilities, which can be attributed to the absence of borrowing.
In this case, the model proposed by Berry et al. (2013) leads to the highest amount of borrowing and therefore, to the best outcome.
In case of ExNex adjusted, the amount of borrowing depends on the similarity of the cohorts. 
<!-- The more similar the cohorts, the higher the amount of borrowing. -->

### Continue Recruitment

After an analysis as above, one can continue the recruitment and add more subjects to the cohorts.
The function [`continueRecruitment()`](https://search.r-project.org/CRAN/refmans/bhmbasket/html/continueRecruitment.html) is used to update the scenario list and to add a specified number of subjects to the current number of subjects of the simulated cohorts.
`continueRecruitment()` only allows to add subjects according to one method.
In this case, *exnex adjusted* will be used to continue the recruitment.

```{r, message=FALSE, warning=FALSE}
set.seed(677643)
final_scenario_list <- continueRecruitment(
  n_subjects_add_list = c(15, 15),
  decisions_list      = futility_decision_list,
  method_name         = "exnex_adj")
 
final_analysis_list <- performAnalyses(
  scenario_list = final_scenario_list, 
  method_names  = "exnex_adj",
  calc_differences = c(2, 1),
  target_rates  = c(0.2, 0.35, 0.3))
```
Only the simulated trial outcomes with an overall Go decision will get additional subjects in the cohorts with cohort-wise Go decisions and only those trial outcomes will be analysed again in `performAnalyses()`.
Due to the different numbers of subjects in the trials, the decision rules can be assessed regarding to the average number of subjects across the different scenarios.
The average number of subjects can be calculated using `getAverageNSubjects()`.

```{r}
getAverageNSubjects(
  scenario_list = final_scenario_list
)
```

### Final Decision Making

In this example, decision making as proposed by [Fisch et al. (2015)](https://link.springer.com/article/10.1177/2168479014533970) is implemented for the final analysis.
This approach leads to a three-way decision making with Go, Consider, and NoGo outcomes based on decision rules labeled significance and relevance.
Each cohort will have a decision boundary for relevance and for significance.
To receive a Go decision, relevance and significance must be true.
If both criteria are false, the decision will be a NoGo.
If either relevance or significance is true, it will be a Consider.

#### Implementation of Decision Rules According to Fisch et al. (2015)

Decision rules following the framework proposed by Fisch et al. (2015) are implemented in a similar way as presented above.
<!-- To get a Consider decision and its probability, it is not enough to just negate the Go decision list, using `negateGoDecisions(decision_list)`. -->
<!-- It is necessary to set up another set of decision rules and negate them afterwards. -->
For each cohort, the Go and NoGo decision rules can be represented as a conjunction of relevance and significance. The set up of these rules is depict below.

Go: $R ∧ S$   
NoGo: $-R ∧ -S  = -(R ∨ S)$  
else Consider

To implement the NoGo rule, $-(R ∨ S)$, the function `negateGoDecisions()` can be used in conjunction with `getGoDecisions()`.
As an example, decision rules applying relevance and significance can be implemented as follows:

Relevance: $P(p_1|\text{data} > 0.8) > 0.5$  
Significance: $P(p_1|\text{data} > 0.4) > 0.95$


```{r, eval=FALSE}
cohort_names    = c('p_1', 'p_2',
                    'p_1', 'p_2')
evidence_levels = c(0.5, 0.5,
                    0.95, 0.95)

# argument for first call of getGoDecisions()
go_boundary_rules   = quote(c(x[1] > 0.8 & x[3] > 0.4, 
                              x[2] > 0.8 & x[4] > 0.4)

# argument for second call of getGoDecisions() with negateGoDecisions()
nogo_boundary_rules = quote(c(x[1] > 0.8 | x[3] > 0.4, 
                              x[2] > 0.8 | x[4] > 0.4)
```

#### Final Decision Example Trial

<!-- The decision making proposed by Fisch et al. (2015) implies that another set of decision rules is required as above. -->
<!-- The entire implementation of this decision rules is implemented as follows: -->

For the final analysis of this example, the decision rules for Cohort 1 for relevance and significance are $P(p_1|\text{data} > 0.147) > 0.5 $ and $P(p_1|\text{data} > 0.05) > 0.8$, respectively.
In Cohort 2, the relevance criteria $P(p_2|\text{data} > 0.28) > 0.5$ ∧ $P(p_2-p_1|\text{data} > 0) > 0.5 $ is a combination of boundary rules for the point estimate and the difference between Cohort 2 and 1.
The rules for significance is implemented with $P(p_2|\text{data} > 0.15) > 0.8$.
The third cohort should not get a decision as well as in the futility analysis and therefore, `boundary_rules` contains the value `TRUE` on the third position.


```{r}
final_decision_list <- getGoDecisions(
  analyses_list   = final_analysis_list,
  cohort_names    = c("p_1", "p_2", "p_diff_21", 
                      "p_1", "p_2"),
  evidence_levels = c(0.5, 0.5, 0.5,
                      0.8, 0.8),
  boundary_rules  = quote(c(x[1] > 0.147           & x[4] > 0.05,
                            x[2] > 0.28  & x[3] > 0 & x[5] > 0.15, 
                            TRUE)),
  overall_min_gos = 2)


final_nogo_decision_list <- negateGoDecisions(
  getGoDecisions(
    analyses_list   = final_analysis_list,
    cohort_names    = c("p_1", "p_2", "p_diff_21", 
                        "p_1", "p_2"),
    evidence_levels = c(0.5, 0.5, 0.5,
                        0.8, 0.8), 
    boundary_rules  = quote(c(x[1] > 0.147            | x[4] > 0.05,
                              x[2] > 0.28  & x[3] > 0 | x[5] > 0.15,
                              TRUE)),
    overall_min_gos = 2),
  overall_min_nogos = 2)

final_probability_list <- getGoProbabilities(
  go_decisions_list = final_decision_list,
  nogo_decisions_list = final_nogo_decision_list)

scaleRoundList(final_probability_list, round_digits = 2)
```

It is always a trade-off sample size and required go probabilities.
In this case, the sets of decision rules lead to an overall Go probability of 88% and individual Go probabilities of 68% in Cohort 1 and 70% in Cohort 2. 
The probabilities of identifying the nugget cohorts are 60% and 65%.
In the negative scenario, the overall Go probability is 11%.
